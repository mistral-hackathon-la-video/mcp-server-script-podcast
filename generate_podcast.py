#!/usr/bin/env python3
"""
Podcast Generator

Converts text scripts generated by generate_script.py into audio podcasts
using Kokoro-TTS and ElevenLabs text-to-speech engines.

Usage:
    python generate_podcast.py --script "path/to/script.txt" --output "podcast.wav"
"""

import asyncio
import os
import re
import tempfile
import logging
from pathlib import Path
from typing import List, Tuple, Optional, Literal
from dataclasses import dataclass
import argparse

# Audio processing
import soundfile as sf
import numpy as np

# TTS engines (conditional imports)
# Temporarily disable Kokoro due to pip module issues during initialization
kokoro = None
KOKORO_AVAILABLE = False

# try:
#     import kokoro
#     KOKORO_AVAILABLE = True
# except Exception as e:
#     # Catch any import errors, including those from dependencies
#     kokoro = None
#     KOKORO_AVAILABLE = False
    
try:
    from elevenlabs import ElevenLabs, VoiceSettings
    ELEVENLABS_AVAILABLE = True
except Exception:
    ElevenLabs = None
    VoiceSettings = None
    ELEVENLABS_AVAILABLE = False

# Environment and utilities
from dotenv import load_dotenv

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

@dataclass
class AudioSegment:
    """Represents a segment of audio with metadata."""
    text: str
    component_type: str
    audio_data: np.ndarray
    sample_rate: int
    duration: float
    voice_used: str

@dataclass 
class PodcastConfig:
    """Configuration for podcast generation."""
    # TTS Engine selection
    tts_engine: Literal["kokoro", "elevenlabs", "mixed"] = "mixed"
    
    # Voice settings
    headline_voice: str = "narrator"  # For headlines 
    text_voice: str = "host"         # For main text
    
    # Audio settings
    sample_rate: int = 24000
    silence_duration: float = 0.5    # Seconds of silence between segments
    headline_silence: float = 1.0    # Extra silence after headlines
    
    # ElevenLabs settings  
    elevenlabs_stability: float = 0.5
    elevenlabs_similarity: float = 0.8
    elevenlabs_style: float = 0.2
    
    # Output settings
    normalize_audio: bool = True
    output_format: str = "wav"       # wav, mp3, etc.


class PodcastGenerator:
    """Main class for generating podcasts from scripts."""
    
    def __init__(self, config: PodcastConfig = None):
        self.config = config or PodcastConfig()
        self.temp_files = []
        
        # Lazy initialization - engines will be initialized when needed
        self.kokoro_pipeline = None
        self.elevenlabs = None
        self._tts_initialized = False
    
    def _ensure_tts_initialized(self):
        """Initialize TTS engines lazily when needed."""
        if self._tts_initialized:
            return
            
        self._init_tts_engines()
        self._tts_initialized = True
    
    def _init_tts_engines(self):
        """Initialize the TTS engines based on configuration."""
        
        # Initialize Kokoro TTS
        self.kokoro_pipeline = None
        if KOKORO_AVAILABLE and self.config.tts_engine in ["kokoro", "mixed"]:
            try:
                # Initialize with American English as default
                self.kokoro_pipeline = kokoro.pipeline.KPipeline('a', repo_id='hexgrad/Kokoro-82M')
                logger.info("âœ… Kokoro TTS initialized successfully")
            except Exception as e:
                logger.warning(f"âš ï¸  Kokoro TTS initialization failed: {e}")
                logger.info("ðŸ“ Will use mock audio generation for testing")
        elif not KOKORO_AVAILABLE:
            logger.info("ðŸ“ Kokoro not available, will use mock audio for testing")
        
        # Initialize ElevenLabs
        self.elevenlabs = None
        if ELEVENLABS_AVAILABLE:
            elevenlabs_api_key = os.getenv("ELEVENLABS_API_KEY")
            if elevenlabs_api_key:
                try:
                    self.elevenlabs = ElevenLabs(api_key=elevenlabs_api_key)
                    logger.info("âœ… ElevenLabs initialized successfully")
                except Exception as e:
                    logger.warning(f"âš ï¸  ElevenLabs initialization failed: {e}")
            else:
                logger.warning("âš ï¸  ELEVENLABS_API_KEY not found in environment")
        else:
            logger.info("ðŸ“ ElevenLabs not available")

    def parse_script(self, script_text: str) -> List[Tuple[str, str]]:
        """
        Parse the script text into components.
        
        Args:
            script_text: Raw script text from generate_script.py
            
        Returns:
            List of (component_type, content) tuples
        """
        components = []
        lines = script_text.strip().split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Match the format: \ComponentType: Content (from reconstruct_script output)
            match = re.match(r'^\\(Headline|Text):\s*(.+)$', line)
            if match:
                component_type, content = match.groups()
                components.append((component_type.strip(), content.strip()))
            else:
                # If line doesn't match expected format, treat as text
                if line.startswith('\\'):
                    continue  # Skip malformed lines
                components.append(("Text", line))
                
        logger.info(f"ðŸ“ Parsed {len(components)} script components")
        return components

    async def generate_audio_kokoro(self, text: str, voice: str = "a") -> Tuple[np.ndarray, int]:
        """
        Generate audio using Kokoro TTS.
        
        Args:
            text: Text to synthesize
            voice: Voice identifier ('a'=American, 'b'=British, etc.)
            
        Returns:
            Tuple of (audio_data, sample_rate)
        """
        if not self.kokoro_pipeline:
            raise RuntimeError("Kokoro TTS not available")
            
        try:
            # Clean text for TTS
            clean_text = self._clean_text_for_tts(text)
            
            # Generate audio with Kokoro pipeline (lang already set in pipeline)
            audio_data = self.kokoro_pipeline(clean_text)
            
            # Convert to numpy array and get sample rate
            if hasattr(audio_data, 'numpy'):
                audio_array = audio_data.numpy().squeeze()
            else:
                audio_array = np.array(audio_data).squeeze()
            
            # Kokoro typically outputs at 24kHz
            sample_rate = 24000
            
            logger.debug(f"ðŸŽµ Generated {len(audio_array)/sample_rate:.2f}s audio with Kokoro")
            return audio_array, sample_rate
            
        except Exception as e:
            logger.error(f"âŒ Kokoro TTS generation failed: {e}")
            raise

    async def generate_audio_elevenlabs(self, text: str, voice: str = "21m00Tcm4TlvDq8ikWAM") -> Tuple[np.ndarray, int]:
        """
        Generate audio using ElevenLabs.
        
        Args:
            text: Text to synthesize  
            voice: ElevenLabs voice ID
            
        Returns:
            Tuple of (audio_data, sample_rate)
        """
        if not self.elevenlabs:
            raise RuntimeError("ElevenLabs not available")
            
        try:
            # Clean text for TTS
            clean_text = self._clean_text_for_tts(text)
            
            # Configure voice settings
            if VoiceSettings:
                voice_settings = VoiceSettings(
                    stability=self.config.elevenlabs_stability,
                    similarity_boost=self.config.elevenlabs_similarity,
                    style=self.config.elevenlabs_style
                )
            else:
                voice_settings = None
            
            # Generate audio
            audio_generator = self.elevenlabs.generate(
                text=clean_text,
                voice=voice,
                voice_settings=voice_settings,
                model="eleven_multilingual_v2"
            )
            
            # Collect audio bytes
            audio_bytes = b"".join(audio_generator)
            
            # Save to temp file and load with soundfile  
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                tmp_file.write(audio_bytes)
                tmp_file_path = tmp_file.name
                self.temp_files.append(tmp_file_path)
            
            # Load audio data
            audio_data, sample_rate = sf.read(tmp_file_path)
            
            logger.debug(f"ðŸŽµ Generated {len(audio_data)/sample_rate:.2f}s audio with ElevenLabs")
            return audio_data, sample_rate
            
        except Exception as e:
            logger.error(f"âŒ ElevenLabs TTS generation failed: {e}")
            raise

    def _clean_text_for_tts(self, text: str) -> str:
        """
        Clean and prepare text for TTS synthesis.
        
        Args:
            text: Raw text
            
        Returns:
            Cleaned text suitable for TTS
        """
        # Remove markdown formatting
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # Bold
        text = re.sub(r'\*(.*?)\*', r'\1', text)      # Italic
        text = re.sub(r'`(.*?)`', r'\1', text)        # Code
        
        # Remove URLs (but keep the text)
        text = re.sub(r'https?://[^\s]+', '', text)
        
        # Clean up special characters
        text = re.sub(r'[^\w\s.,!?;:()\'-]', ' ', text)
        
        # Normalize whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text

    async def generate_audio_segment(self, text: str, component_type: str) -> AudioSegment:
        """
        Generate audio for a single script component.
        
        Args:
            text: Text content
            component_type: "Headline" or "Text"
            
        Returns:
            AudioSegment with generated audio
        """
        # Ensure TTS engines are initialized
        self._ensure_tts_initialized()
        
        # Select voice and TTS engine based on component type
        if component_type == "Headline":
            voice = self.config.headline_voice
            prefer_engine = "elevenlabs"  # Use ElevenLabs for headlines (more dramatic)
        else:
            voice = self.config.text_voice
            prefer_engine = "kokoro"      # Use Kokoro for main text (more natural)
        
        # Try preferred engine first, fallback to available one
        audio_data, sample_rate = None, None
        voice_used = None
        
        try:
            if self.config.tts_engine == "mixed":
                engine = prefer_engine
            else:
                engine = self.config.tts_engine
                
            if engine == "elevenlabs" and self.elevenlabs:
                audio_data, sample_rate = await self.generate_audio_elevenlabs(text, voice)
                voice_used = f"ElevenLabs-{voice}"
            elif engine == "kokoro" and self.kokoro_pipeline:
                audio_data, sample_rate = await self.generate_audio_kokoro(text, voice)
                voice_used = f"Kokoro-{voice}"
            else:
                # Fallback
                if self.kokoro_pipeline:
                    audio_data, sample_rate = await self.generate_audio_kokoro(text, voice)
                    voice_used = f"Kokoro-{voice}"
                elif self.elevenlabs:
                    audio_data, sample_rate = await self.generate_audio_elevenlabs(text, voice)
                    voice_used = f"ElevenLabs-{voice}"
                else:
                    # Last resort: generate mock audio for testing
                    audio_data, sample_rate = self._generate_mock_audio(text)
                    voice_used = "Mock-TTS"
        
        except Exception as e:
            logger.error(f"âŒ Failed to generate audio for: {text[:50]}...")
            raise
        
        # Resample if necessary
        if sample_rate != self.config.sample_rate:
            # Simple resampling (you might want to use librosa for better quality)
            audio_data = self._resample_audio(audio_data, sample_rate, self.config.sample_rate)
            sample_rate = self.config.sample_rate
        
        duration = len(audio_data) / sample_rate
        
        return AudioSegment(
            text=text,
            component_type=component_type,
            audio_data=audio_data,
            sample_rate=sample_rate,
            duration=duration,
            voice_used=voice_used
        )

    def _resample_audio(self, audio: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:
        """Simple audio resampling (basic implementation)."""
        if orig_sr == target_sr:
            return audio
            
        # Basic linear interpolation resampling
        ratio = target_sr / orig_sr
        new_length = int(len(audio) * ratio)
        indices = np.linspace(0, len(audio) - 1, new_length)
        return np.interp(indices, np.arange(len(audio)), audio)

    def create_silence(self, duration: float) -> np.ndarray:
        """Create silence of specified duration."""
        return np.zeros(int(duration * self.config.sample_rate))

    def _generate_mock_audio(self, text: str) -> Tuple[np.ndarray, int]:
        """Generate mock audio for testing when no TTS engines are available."""
        # Estimate duration based on text length (average reading speed)
        words = len(text.split())
        duration = max(1.0, words * 0.4)  # ~2.5 words per second
        
        # Generate a simple sine wave tone
        sample_rate = self.config.sample_rate
        samples = int(duration * sample_rate)
        t = np.linspace(0, duration, samples, False)
        
        # Create a pleasant tone (440Hz with some harmonics)
        frequency = 440.0  # A4 note
        audio = (np.sin(2 * np.pi * frequency * t) * 0.3 + 
                np.sin(2 * np.pi * frequency * 2 * t) * 0.1 + 
                np.sin(2 * np.pi * frequency * 3 * t) * 0.05)
        
        # Apply envelope to avoid clicks
        envelope_length = int(0.1 * sample_rate)  # 100ms fade in/out
        if len(audio) > 2 * envelope_length:
            fade_in = np.linspace(0, 1, envelope_length)
            fade_out = np.linspace(1, 0, envelope_length)
            audio[:envelope_length] *= fade_in
            audio[-envelope_length:] *= fade_out
        
        logger.debug(f"ðŸŽµ Generated {duration:.2f}s mock audio for: {text[:30]}...")
        return audio, sample_rate

    async def generate_podcast(self, script_text: str, output_path: str = None) -> str:
        """
        Generate a complete podcast from script text.
        
        Args:
            script_text: Script output from generate_script.py
            output_path: Output file path (optional)
            
        Returns:
            Path to generated podcast file
        """
        logger.info("ðŸŽ™ï¸ Starting podcast generation...")
        
        # Parse script components
        components = self.parse_script(script_text)
        if not components:
            raise ValueError("No valid script components found")
        
        # Generate audio for each component
        audio_segments = []
        total_duration = 0
        
        for i, (component_type, text) in enumerate(components):
            logger.info(f"ðŸŽµ Generating audio {i+1}/{len(components)}: {component_type}")
            logger.debug(f"ðŸ“ Text: {text[:100]}{'...' if len(text) > 100 else ''}")
            
            try:
                segment = await self.generate_audio_segment(text, component_type)
                audio_segments.append(segment)
                total_duration += segment.duration
                logger.info(f"âœ… Generated {segment.duration:.2f}s with {segment.voice_used}")
            except Exception as e:
                logger.error(f"âŒ Failed to generate segment {i+1}: {e}")
                continue
        
        if not audio_segments:
            raise RuntimeError("Failed to generate any audio segments")
        
        # Combine audio segments
        logger.info(f"ðŸ”§ Combining {len(audio_segments)} audio segments...")
        combined_audio = self._combine_audio_segments(audio_segments)
        
        # Normalize audio if requested
        if self.config.normalize_audio:
            combined_audio = self._normalize_audio(combined_audio)
        
        # Generate output filename if not provided
        if not output_path:
            output_path = f"podcast_{len(components)}_segments.{self.config.output_format}"
        
        # Save final podcast
        sf.write(output_path, combined_audio, self.config.sample_rate)
        
        # Cleanup temp files
        self._cleanup_temp_files()
        
        final_duration = len(combined_audio) / self.config.sample_rate
        logger.info(f"ðŸŽ‰ Podcast generated successfully!")
        logger.info(f"ðŸ“Š Final duration: {final_duration:.2f}s ({final_duration/60:.1f} minutes)")
        logger.info(f"ðŸ’¾ Saved to: {output_path}")
        
        return output_path

    def _combine_audio_segments(self, segments: List[AudioSegment]) -> np.ndarray:
        """Combine audio segments with appropriate silence."""
        combined = []
        
        for i, segment in enumerate(segments):
            # Add the audio segment
            combined.append(segment.audio_data)
            
            # Add silence after segment (except last one)
            if i < len(segments) - 1:
                if segment.component_type == "Headline":
                    silence_duration = self.config.headline_silence
                else:
                    silence_duration = self.config.silence_duration
                
                silence = self.create_silence(silence_duration)
                combined.append(silence)
        
        return np.concatenate(combined)

    def _normalize_audio(self, audio: np.ndarray) -> np.ndarray:
        """Normalize audio to prevent clipping."""
        max_val = np.max(np.abs(audio))
        if max_val > 0:
            return audio * (0.95 / max_val)
        return audio

    def _cleanup_temp_files(self):
        """Clean up temporary files."""
        for temp_file in self.temp_files:
            try:
                os.unlink(temp_file)
            except:
                pass
        self.temp_files.clear()

    def __del__(self):
        """Cleanup on destruction."""
        self._cleanup_temp_files()


async def main():
    """CLI interface for podcast generation."""
    parser = argparse.ArgumentParser(description="Generate podcasts from scripts")
    parser.add_argument("--script", required=True, help="Path to script file or script text")
    parser.add_argument("--output", help="Output podcast file path")
    parser.add_argument("--engine", choices=["kokoro", "elevenlabs", "mixed"], 
                       default="mixed", help="TTS engine to use")
    parser.add_argument("--sample-rate", type=int, default=24000, help="Audio sample rate")
    parser.add_argument("--format", default="wav", help="Output audio format")
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose logging")
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Configure podcast generation
    config = PodcastConfig(
        tts_engine=args.engine,
        sample_rate=args.sample_rate,
        output_format=args.format
    )
    
    # Load script text
    script_path = Path(args.script)
    if script_path.exists():
        script_text = script_path.read_text(encoding='utf-8')
    else:
        # Treat as direct script text
        script_text = args.script
    
    # Generate podcast
    generator = PodcastGenerator(config)
    try:
        output_path = await generator.generate_podcast(script_text, args.output)
        print(f"âœ… Podcast generated: {output_path}")
    except Exception as e:
        logger.error(f"âŒ Podcast generation failed: {e}")
        return 1
    
    return 0


def generate_podcast_from_script(script_text: str, output_path: str = None, **kwargs) -> str:
    """
    Convenient function to generate podcast from script text.
    
    Args:
        script_text: Script output from generate_script.py
        output_path: Optional output path
        **kwargs: Additional configuration options
        
    Returns:
        Path to generated podcast file
    """
    config = PodcastConfig(**kwargs)
    generator = PodcastGenerator(config)
    
    # Check if we're already in an async context
    try:
        loop = asyncio.get_running_loop()
        # We're in an async context, create a task
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(asyncio.run, generator.generate_podcast(script_text, output_path))
            return future.result()
    except RuntimeError:
        # No running loop, safe to use asyncio.run()
        return asyncio.run(generator.generate_podcast(script_text, output_path))


if __name__ == "__main__":
    import sys
    sys.exit(asyncio.run(main()))